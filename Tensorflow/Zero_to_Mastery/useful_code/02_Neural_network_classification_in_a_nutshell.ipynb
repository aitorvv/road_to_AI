{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+fJDVxih1WMtlXnR1cmG2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aitorvv96/road_to_AI/blob/main/Tensorflow/Zero_to_Mastery/useful_code/02_Neural_network_classification_in_a_nutshell.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 02. Neural Network Classification with TensorFlow\n",
        "\n",
        "You might want to:\n",
        "* Predict whether or not someone has heart disease based on their health parameters. This is called **binary classification** since there are only two options.\n",
        "* Decide whether a photo of is of food, a person or a dog. This is called **multi-class classification** since there are more than two options.\n",
        "* Predict what categories should be assigned to a Wikipedia article. This is called **multi-label classification** since a single article could have more than one category assigned."
      ],
      "metadata": {
        "id": "9lEtOe5xdvoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Typical architecture of a classification neural network \n",
        "\n",
        "The following are some standard values you'll often use in your classification neural networks.\n",
        "\n",
        "| **Hyperparameter** | **Binary Classification** | **Multiclass classification** |\n",
        "| --- | --- | --- |\n",
        "| Input layer shape | Same as number of features (e.g. 5 for age, sex, height, weight, smoking status in heart disease prediction) | Same as binary classification |\n",
        "| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited | Same as binary classification |\n",
        "| Neurons per hidden layer | Problem specific, generally 10 to 100 | Same as binary classification |\n",
        "| Output layer shape | 1 (one class or the other) | 1 per class (e.g. 3 for food, person or dog photo) |\n",
        "| Hidden activation | Usually [ReLU](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) (rectified linear unit) | Same as binary classification |\n",
        "| Output activation | [Sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) | [Softmax](https://en.wikipedia.org/wiki/Softmax_function) |\n",
        "| Loss function | [Cross entropy](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression) ([`tf.keras.losses.BinaryCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy) in TensorFlow) | Cross entropy ([`tf.keras.losses.CategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) in TensorFlow) |\n",
        "| Optimizer | [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) (stochastic gradient descent), [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) | Same as binary classification |\n",
        "\n",
        "***Table 1:*** *Typical architecture of a classification network.* ***Source:*** *Adapted from page 295 of [Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by Aurélien Géron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)*\n"
      ],
      "metadata": {
        "id": "fzhD7TGpeLhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create data to view and fit"
      ],
      "metadata": {
        "id": "YrnPHPJneR0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and output shapes\n",
        "\n",
        "Shape mismatches is one of the most common issues when building neural networks."
      ],
      "metadata": {
        "id": "5z2oHU9jeUkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shapes of our features and labels\n",
        "X.shape, y.shape\n",
        "# Check how many samples we have\n",
        "len(X), len(y)\n",
        "# View an example of features and labels\n",
        "X[0], y[0]"
      ],
      "metadata": {
        "id": "1pCMxzBqeVru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling\n",
        "\n",
        "In TensorFlow, there are typically 3 fundamental steps to creating and training a model:\n",
        "1. **Creating a model** - piece together the layers of a neural network yourself (using the [functional](https://www.tensorflow.org/guide/keras/functional) or [sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)) or import a previously built model (known as transfer learning).\n",
        "2. **Compiling a model** - defining how a model's performance should be measured (loss/metrics) as well as defining how it should improve (optimizer). \n",
        "3. **Fitting a model** - letting the model try to find patterns in the data (how does `X` get to `y`). "
      ],
      "metadata": {
        "id": "4rbTc1NYeaYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.SGD(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "history_m1 = model_1.fit(X, y, epochs=10)\n",
        "\n",
        "# 4. Evaluate the model\n",
        "model_1.evaluate(X, y)"
      ],
      "metadata": {
        "id": "wmhrBf3meeu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving a model\n",
        "\n",
        "To improve our model, we can alter almost every part of the 3 steps we went through before.\n",
        "\n",
        "1. **Creating a model** - here you might want to add more layers, increase the number of hidden units (also called neurons) within each layer, change the activation functions of each layer.\n",
        "2. **Compiling a model** - you might want to choose a different optimization function (such as the [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) optimizer, which is usually pretty good for many problems) or perhaps change the learning rate of the optimization function.\n",
        "3. **Fitting a model** - perhaps you could fit a model for more epochs (leave it training for longer).\n",
        "\n",
        "![various options you can use to improve a neural network model](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/02-improving-a-model-from-model-perspective.png)\n",
        "*There are many different ways to potentially improve a neural network. Some of the most common include: increasing the number of layers (making the network deeper), increasing the number of hidden units (making the network wider) and changing the learning rate. Because these values are all human-changeable, they're referred to as [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) and the practice of trying to find the best hyperparameters is referred to as [hyperparameter tuning](https://en.wikipedia.org/wiki/Hyperparameter_optimization).*\n",
        "\n",
        "To visualize our model's predictions we're going to create a function `plot_decision_boundary()` which:\n",
        "* Takes in a trained model, features (`X`) and labels (`y`).\n",
        "* Creates a [meshgrid](https://numpy.org/doc/stable/reference/generated/numpy.meshgrid.html) of the different `X` values.\n",
        "* Makes predictions across the meshgrid.\n",
        "* Plots the predictions as well as a line between the different zones (where each unique class falls)."
      ],
      "metadata": {
        "id": "9FBKFjnNehwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def plot_decision_boundary(model, X, y):\n",
        "  \"\"\"\n",
        "  Plots the decision boundary created by a model predicting on X.\n",
        "  This function has been adapted from two phenomenal resources:\n",
        "   1. CS231n - https://cs231n.github.io/neural-networks-case-study/\n",
        "   2. Made with ML basics - https://github.com/GokuMohandas/MadeWithML/blob/main/notebooks/08_Neural_Networks.ipynb\n",
        "  \"\"\"\n",
        "  # Define the axis boundaries of the plot and create a meshgrid\n",
        "  x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "  y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
        "  xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                       np.linspace(y_min, y_max, 100))\n",
        "  \n",
        "  # Create X values (we're going to predict on all of these)\n",
        "  x_in = np.c_[xx.ravel(), yy.ravel()] # stack 2D arrays together: https://numpy.org/devdocs/reference/generated/numpy.c_.html\n",
        "  \n",
        "  # Make predictions using the trained model\n",
        "  y_pred = model.predict(x_in)\n",
        "\n",
        "  # Check for multi-class\n",
        "  if model.output_shape[-1] > 1: # checks the final dimension of the model's output shape, if this is > (greater than) 1, it's multi-class \n",
        "    print(\"doing multiclass classification...\")\n",
        "    # We have to reshape our predictions to get them ready for plotting\n",
        "    y_pred = np.argmax(y_pred, axis=1).reshape(xx.shape)\n",
        "  else:\n",
        "    print(\"doing binary classifcation...\")\n",
        "    y_pred = np.round(np.max(y_pred, axis=1)).reshape(xx.shape)\n",
        "  \n",
        "  # Plot decision boundary\n",
        "  plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n",
        "  plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
        "  plt.xlim(xx.min(), xx.max())\n",
        "  plt.ylim(yy.min(), yy.max())"
      ],
      "metadata": {
        "id": "3pV8xjszenKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the predictions our model is making\n",
        "plot_decision_boundary(model_1, X, y)"
      ],
      "metadata": {
        "id": "3GIGZntbepJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with our trained model\n",
        "y_reg_preds = model_3.predict(y_reg_test)\n",
        "\n",
        "# Plot the model's predictions against our regression data\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(X_reg_train, y_reg_train, c='b', label='Training data')\n",
        "plt.scatter(X_reg_test, y_reg_test, c='g', label='Testing data')\n",
        "plt.scatter(X_reg_test, y_reg_preds.squeeze(), c='r', label='Predictions')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "HHXRPTAkexQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The missing piece: non-linearity"
      ],
      "metadata": {
        "id": "SI9bggoXezSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating and improving our classification model"
      ],
      "metadata": {
        "id": "OP8eqWlNe2zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our model on the test set\n",
        "loss, accuracy = model_8.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {100*accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "9jiH8diHe776"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the loss curves"
      ],
      "metadata": {
        "id": "FxYmdH4Pe9IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can access the information in the history variable using the .history attribute\n",
        "pd.DataFrame(history.history)"
      ],
      "metadata": {
        "id": "zAl03qcZfAeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curves\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.title(\"Model_8 training curves\")"
      ],
      "metadata": {
        "id": "qwe-wGlffCt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the best learning rate\n",
        "\n",
        "To do so, we're going to use the following:\n",
        "* A [learning rate **callback**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler).\n",
        "   * You can think of a callback as an extra piece of functionality you can add to your model *while* its training.\n",
        "* Another model (we could use the same ones as above, we we're practicing building models here).\n",
        "* A modified loss curves plot."
      ],
      "metadata": {
        "id": "qDQXj0OHfENH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model (same as model_8)\n",
        "model_9 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_9.compile(loss=\"binary_crossentropy\", # we can use strings here too\n",
        "              optimizer=\"Adam\", # same as tf.keras.optimizers.Adam() with default settings\n",
        "              metrics=[\"accuracy\"]) \n",
        "\n",
        "# Create a learning rate scheduler callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20)) # traverse a set of learning rate values starting from 1e-4, increasing by 10**(epoch/20) every epoch\n",
        "\n",
        "# Fit the model (passing the lr_scheduler callback)\n",
        "history = model_9.fit(X_train, \n",
        "                      y_train, \n",
        "                      epochs=100,\n",
        "                      callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "_hFVepowfGBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning rate versus the loss\n",
        "lrs = 1e-4 * (10 ** (np.arange(100)/20))\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.semilogx(lrs, history.history[\"loss\"]) # we want the x-axis (learning rate) to be log scale\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Learning rate vs. loss\");"
      ],
      "metadata": {
        "id": "KHfpEDGHfJi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To figure out the ideal value of the learning rate (at least the ideal value to *begin* training our model), the rule of thumb is to take the learning rate value where the loss is still decreasing but not quite flattened out (usually about 10x smaller than the bottom of the curve).\n",
        "\n",
        "In this case, our ideal learning rate ends up between `0.01` ($10^{-2}$) and `0.02`.\n",
        "\n",
        "![finding the ideal learning rate by plotting learning rate vs. loss](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/02-learning-rate-vs-loss.png)\n",
        "\n",
        "*The ideal learning rate at the start of model training is somewhere just before the loss curve bottoms out (a value where the loss is still decreasing).*"
      ],
      "metadata": {
        "id": "H_FdXZsnfKwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More classification evaluation methods\n",
        "\n",
        "Alongside the visualizations we've been making, there are a number of different evaluation metrics we can use to evaluate our classification models.\n",
        "\n",
        "| **Metric name/Evaluation method** | **Defintion** | **Code** |\n",
        "| --- | --- | --- |\n",
        "| Accuracy | Out of 100 predictions, how many does your model get correct? E.g. 95% accuracy means it gets 95/100 predictions correct. | [`sklearn.metrics.accuracy_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) or [`tf.keras.metrics.Accuracy()`](tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy) |\n",
        "| Precision | Proportion of true positives over total number of samples. Higher precision leads to less false positives (model predicts 1 when it should've been 0). | [`sklearn.metrics.precision_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html) or [`tf.keras.metrics.Precision()`](tensorflow.org/api_docs/python/tf/keras/metrics/Precision) |\n",
        "| Recall | Proportion of true positives over total number of true positives and false negatives (model predicts 0 when it should've been 1). Higher recall leads to less false negatives. | [`sklearn.metrics.recall_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html) or [`tf.keras.metrics.Recall()`](tensorflow.org/api_docs/python/tf/keras/metrics/Recall) |\n",
        "| F1-score | Combines precision and recall into one metric. 1 is best, 0 is worst. | [`sklearn.metrics.f1_score()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) |\n",
        "| [Confusion matrix](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)  | Compares the predicted values with the true values in a tabular way, if 100% correct, all values in the matrix will be top left to bottom right (diagnol line). | Custom function or [`sklearn.metrics.plot_confusion_matrix()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html) |\n",
        "| Classification report | Collection of some of the main classification metrics such as precision, recall and f1-score. | [`sklearn.metrics.classification_report()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) |"
      ],
      "metadata": {
        "id": "pETA_bQcfOL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about a confusion matrix?\n",
        "\n",
        "![anatomy of a confusion matrix](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/02-anatomy-of-a-confusion-matrix.png)\n",
        "*Anatomy of a confusion matrix (what we're going to be creating). Correct predictions appear down the diagonal (from top left to bottom right).*\n",
        "\n",
        "We can make a confusion matrix using [Scikit-Learn's `confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) method."
      ],
      "metadata": {
        "id": "ggLsd6nnfQ_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: The following confusion matrix code is a remix of Scikit-Learn's \n",
        "# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
        "# and Made with ML's introductory notebook - https://github.com/GokuMohandas/MadeWithML/blob/main/notebooks/08_Neural_Networks.ipynb\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Our function needs a different name to sklearn's plot_confusion_matrix\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15): \n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "  \n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"  \n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "  \n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes), \n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "  \n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "             size=text_size)"
      ],
      "metadata": {
        "id": "wKyPPed-fnSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with a larger example (multiclass classification)"
      ],
      "metadata": {
        "id": "I0w4IdKgflV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot multiple random images of fashion MNIST\n",
        "import random\n",
        "plt.figure(figsize=(7, 7))\n",
        "for i in range(4):\n",
        "  ax = plt.subplot(2, 2, i + 1)\n",
        "  rand_index = random.choice(range(len(train_data)))\n",
        "  plt.imshow(train_data[rand_index], cmap=plt.cm.binary)\n",
        "  plt.title(class_names[train_labels[rand_index]])\n",
        "  plt.axis(False)"
      ],
      "metadata": {
        "id": "DQjkzdjBfsnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide train and test images by the maximum value (normalize it)\n",
        "train_data = train_data / float(train_data.max())\n",
        "test_data = test_data / float(train_data.max())\n",
        "\n",
        "# Check the min and max values of the training data\n",
        "train_data.min(), train_data.max()"
      ],
      "metadata": {
        "id": "-KeZNUcWfuk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create the model\n",
        "model_11 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer (we had to reshape 28x28 to 784, the Flatten layer does this for us)\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"softmax\") # output shape is 10, activation is softmax\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_11.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), # different loss function for multiclass classifcation\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "non_norm_history = model_11.fit(train_data,\n",
        "                                train_labels,\n",
        "                                epochs=10,\n",
        "                                validation_data=(test_data, test_labels)) # see how the model performs on the test set during training"
      ],
      "metadata": {
        "id": "FX2ZvJJUfvhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Create a function for plotting a random image along with its prediction\n",
        "def plot_random_image(model, images, true_labels, classes):\n",
        "  \"\"\"Picks a random image, plots it and labels it with a predicted and truth label.\n",
        "\n",
        "  Args:\n",
        "    model: a trained model (trained on data similar to what's in images).\n",
        "    images: a set of random images (in tensor form).\n",
        "    true_labels: array of ground truth labels for images.\n",
        "    classes: array of class names for images.\n",
        "  \n",
        "  Returns:\n",
        "    A plot of a random image from `images` with a predicted class label from `model`\n",
        "    as well as the truth class label from `true_labels`.\n",
        "  \"\"\" \n",
        "  # Setup random integer\n",
        "  i = random.randint(0, len(images))\n",
        "  \n",
        "  # Create predictions and targets\n",
        "  target_image = images[i]\n",
        "  pred_probs = model.predict(target_image.reshape(1, 28, 28)) # have to reshape to get into right size for model\n",
        "  pred_label = classes[pred_probs.argmax()]\n",
        "  true_label = classes[true_labels[i]]\n",
        "\n",
        "  # Plot the target image\n",
        "  plt.imshow(target_image, cmap=plt.cm.binary)\n",
        "\n",
        "  # Change the color of the titles depending on if the prediction is right or wrong\n",
        "  if pred_label == true_label:\n",
        "    color = \"green\"\n",
        "  else:\n",
        "    color = \"red\"\n",
        "\n",
        "  # Add xlabel information (prediction/true label)\n",
        "  plt.xlabel(\"Pred: {} {:2.0f}% (True: {})\".format(pred_label,\n",
        "                                                   100*tf.reduce_max(pred_probs),\n",
        "                                                   true_label),\n",
        "             color=color) # set the color to green or red"
      ],
      "metadata": {
        "id": "XP8ZI2nAf1-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a random image as well as its prediction\n",
        "plot_random_image(model=model_14, \n",
        "                  images=test_data, \n",
        "                  true_labels=test_labels, \n",
        "                  classes=class_names)"
      ],
      "metadata": {
        "id": "74W7SRSjf5Ho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}