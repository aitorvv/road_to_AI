{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Ringa Tech - Clasificador de perros y gatos",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aitorvv96/road_to_AI/blob/main/Tensorflow/Ringa_Tech/Comparacion_modelos-Clasificador_de_perros_y_gatos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fuente:**\n",
        "https://www.youtube.com/watch?v=DbwKbsCWPSg&list=PLZ8REt5zt2Pn0vfJjTAPaDVSACDvnuGiG&index=5  \n",
        "**Otros recursos:**  \n",
        "https://github.com/ringa-tech/clasificador-perros-gatos  "
      ],
      "metadata": {
        "id": "bcINsFVc0xOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datos obtenidos de TensorFlow Datasets.  \n",
        "*Debemos poner el entorno de ejecución para que utilice GPU, así los modelos se entrenarán más rápido.*  \n",
        "  \n",
        "* en el momento que lo pruebo (10/05/2022) el link para la carga de datos no funciona"
      ],
      "metadata": {
        "id": "yXPASxJc1vp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 1: Importar datos**"
      ],
      "metadata": {
        "id": "v7IIGwCT6FWE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-T47pwYw8qr"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "#Descargar el set de datos de perros y gatos\n",
        "datos, metadatos = tfds.load('beans', as_supervised=True, with_info=True)  # https://www.tensorflow.org/datasets/catalog/cats_vs_dogs?hl=en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux4kI-Jvxsqi"
      },
      "source": [
        "#Imprimir los metadatos para revisarlos\n",
        "metadatos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dysfe1mux5nb"
      },
      "source": [
        "#Una forma de mostrar 5 ejemplos del set\n",
        "tfds.as_dataframe(datos['train'].take(5), metadatos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YNZO9GAyFgy"
      },
      "source": [
        "#Otra forma de mostrar ejemplos del set\n",
        "tfds.show_examples(datos['train'], metadatos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 2: manejo de datos**\n",
        "En este apartado:\n",
        "- se redimensionan las imágenes para que todas tengan el mismo tamaño. Para esto, podemos ir probando distintos tamaños de imagen y verlas nosotros mismos, hasta decidir con qué tamaño somo capaces de distinguir bien lo que se ve sin utilizar imágenes demasiado grandes\n",
        "- se pasan las imágenes a B/N\n",
        "- normalizamos los datos"
      ],
      "metadata": {
        "id": "XVg9WWb26KD0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtEYnFkNyN_s"
      },
      "source": [
        "#Manipular y visualizar el set\n",
        "#Lo pasamos a TAMANO_IMG (100x100) y a blanco y negro (solo para visualizar)\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2  # en python, instalar opencv-python\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "TAMANO_IMG=100  # establacer tamaño de la imagen\n",
        "\n",
        "for i, (imagen, etiqueta) in enumerate(datos['train'].take(25)):\n",
        "  imagen = cv2.resize(imagen.numpy(), (TAMANO_IMG, TAMANO_IMG))  # redimensionar imagen\n",
        "  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)  # pasarla a B/N\n",
        "  plt.subplot(5, 5, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(imagen, cmap='gray')  # escala de color gris"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZL-LNzszqm-"
      },
      "source": [
        "#Variable que contendra todos los pares de los datos (imagen y etiqueta) ya modificados (blanco y negro, 100x100)\n",
        "datos_entrenamiento = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformación de imágenes antes de añadirlas a la lista de datos de entrenamiento."
      ],
      "metadata": {
        "id": "EXbHS2QP7UAK"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niuyw2ahzwZy"
      },
      "source": [
        "for i, (imagen, etiqueta) in enumerate(datos['train']): #Todos los datos\n",
        "  imagen = cv2.resize(imagen.numpy(), (TAMANO_IMG, TAMANO_IMG))\n",
        "  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
        "  imagen = imagen.reshape(TAMANO_IMG, TAMANO_IMG, 1) #Cambiar tamano a 100,100,1\n",
        "  datos_entrenamiento.append([imagen, etiqueta])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmRCAO7V0NaF"
      },
      "source": [
        "#Ver los datos del primer indice\n",
        "datos_entrenamiento[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBeI5BBe0Urh"
      },
      "source": [
        "#Ver cuantos datos tengo en la variable\n",
        "len(datos_entrenamiento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9EMU7Lh0ZhJ"
      },
      "source": [
        "#Preparar mis variables X (entradas) y y (etiquetas) separadas\n",
        "\n",
        "X = [] #imagenes de entrada (pixeles)\n",
        "y = [] #etiquetas (perro o gato)\n",
        "\n",
        "for imagen, etiqueta in datos_entrenamiento:\n",
        "  X.append(imagen)\n",
        "  y.append(etiqueta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2Y96d3A0kkI"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN8bd2270t7A"
      },
      "source": [
        "#Normalizar los datos de las X (imagenes). Se pasan a numero flotante y dividen entre 255 para quedar de 0-1 en lugar de 0-255\n",
        "import numpy as np\n",
        "\n",
        "X = np.array(X).astype(float) / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJIGT87l03Yc"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJgbpFP-09RC"
      },
      "source": [
        "#Convertir etiquetas en arreglo simple\n",
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alUTJMCO1BiQ"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 3: entrenar el modelo**\n",
        "Para este ejemplo se van a probar 3 modelos con y sin aumento de datos:\n",
        "- modelo denso\n",
        "- modelo convolucional\n",
        "- modelo convolucional con Droupout de 0.5\n",
        "  \n",
        "Tras entrenar los modelos podemos ver cómo evolucionan utilizando TensorBoard directamente con nuestros datos"
      ],
      "metadata": {
        "id": "r9VTGid28MCy"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOEcN2B117SQ"
      },
      "source": [
        "#Crear los modelos iniciales\n",
        "#Usan sigmoid como salida (en lugar de softmax) para mostrar como podria funcionar con dicha funcion de activacion.\n",
        "#Sigmoid regresa siempre datos entre 0 y 1. Realizamos el entrenamiento para al final considerar que si la respuesta se\n",
        "#acerca a 0, es un gato, y si se acerca a 1, es un perro.\n",
        "\n",
        "modeloDenso = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(100, 100, 1)),\n",
        "  tf.keras.layers.Dense(150, activation='relu'),\n",
        "  tf.keras.layers.Dense(150, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "modeloCNN = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(100, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "modeloCNN2 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(250, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH9e4YSf24hM"
      },
      "source": [
        "#Compilar modelos. Usar crossentropy binario ya que tenemos solo 2 opciones (perro o gato)\n",
        "modeloDenso.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "modeloCNN.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "modeloCNN2.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSbOH3Km3Goj"
      },
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenar modelos."
      ],
      "metadata": {
        "id": "eoKQWaV6-XJh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icpR8Ar73NDx"
      },
      "source": [
        "#La variable de tensorboard se envia en el arreglo de \"callbacks\" (hay otros tipos de callbacks soportados)\n",
        "#En este caso guarda datos en la carpeta indicada en cada epoca, de manera que despues\n",
        "#Tensorboard los lee para hacer graficas\n",
        "tensorboardDenso = TensorBoard(log_dir='logs/denso')\n",
        "modeloDenso.fit(X, y, batch_size=32,\n",
        "                validation_split=0.15,  # con este comando se indica el % de datos que se quieren dejar para test\n",
        "                # IMPORTANTE, en este caso NO se han separado los datos en entrenamiento y test\n",
        "                epochs=100,\n",
        "                callbacks=[tensorboardDenso])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QY68qkI5d5C"
      },
      "source": [
        "tensorboardCNN = TensorBoard(log_dir='logs/cnn')\n",
        "modeloCNN.fit(X, y, batch_size=32,\n",
        "                validation_split=0.15,\n",
        "                epochs=100,\n",
        "                callbacks=[tensorboardCNN])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrTNoLjPAKwK"
      },
      "source": [
        "tensorboardCNN2 = TensorBoard(log_dir='logs/cnn2')\n",
        "modeloCNN2.fit(X, y, batch_size=32,\n",
        "                validation_split=0.15,\n",
        "                epochs=100,\n",
        "                callbacks=[tensorboardCNN2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmRBuHwG5BOY"
      },
      "source": [
        "#Cargar la extension de tensorboard de colab\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando TensorBoard podemos ver que los 3 modelos tienen un problema de sobreajuste. El modelo denso < CNN < CNN2 en cuanto a su ajuste, pero para todos los casos hay mucho margen de mejora."
      ],
      "metadata": {
        "id": "ZV8z9mzq-eW4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_xqqhin5Db_"
      },
      "source": [
        "#Ejecutar tensorboard e indicarle que lea la carpeta \"logs\"\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 4: aumento de datos**\n",
        "A partir de la base de datos original:\n",
        "- vamos a hacer un aumento de datos para mejorar el ajuste de los modelos\n",
        "- entrenar los modelos con los datos aumentados\n",
        "- comparar los resultados con los modelos anteriores\n",
        "  \n",
        "Si en algún momento necesitamos liberar memoria RAM, podemos ejecutar lo siguiente:\n",
        "\n",
        "\n",
        "```\n",
        "import gc\n",
        "gc.collect()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "3S7ODfrZ-7Dc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9aiG_8jHqam"
      },
      "source": [
        "#ver las imagenes de la variable X sin modificaciones por aumento de datos\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(10):\n",
        "  plt.subplot(2, 5, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(X[i].reshape(100, 100), cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t25foGQbH_UD"
      },
      "source": [
        "#Realizar el aumento de datos con varias transformaciones. Al final, graficar 10 como ejemplo\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# en el siguiente comando se hacen todos los cambios deseados\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=15,\n",
        "    zoom_range=[0.7, 1.4],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "datagen.fit(X)\n",
        "\n",
        "plt.figure(figsize=(20,8))\n",
        "\n",
        "for imagen, etiqueta in datagen.flow(X, y, batch_size=10, shuffle=False):\n",
        "  for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(imagen[i].reshape(100, 100), cmap=\"gray\")\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con los datos ampliados creamos los mismos modelos que para el apartado anterior."
      ],
      "metadata": {
        "id": "R3MT5Br__7Xa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tRiHZQdJkug"
      },
      "source": [
        "modeloDenso_AD = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(100, 100, 1)),\n",
        "  tf.keras.layers.Dense(150, activation='relu'),\n",
        "  tf.keras.layers.Dense(150, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "modeloCNN_AD = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(100, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "modeloCNN2_AD = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(250, activation='relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yauyCGC3JsZ7"
      },
      "source": [
        "modeloDenso_AD.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "modeloCNN_AD.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "modeloCNN2_AD.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al usar aumento de datos, entonces sí hay que separar entre datos de entrenamiento y datos de prueba/validación."
      ],
      "metadata": {
        "id": "9bT-XYMvAHO2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K1eEKx_JyAv"
      },
      "source": [
        "#Separar los datos de entrenamiento y los datos de pruebas en variables diferentes\n",
        "\n",
        "len(X) * .85 #19700\n",
        "len(X) - 19700 #3562\n",
        "\n",
        "X_entrenamiento = X[:19700]\n",
        "X_validacion = X[19700:]\n",
        "\n",
        "y_entrenamiento = y[:19700]\n",
        "y_validacion = y[19700:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fgSiSBwKE75"
      },
      "source": [
        "#Usar la funcion flow del generador para crear un iterador que podamos enviar como entrenamiento a la funcion FIT del modelo\n",
        "data_gen_entrenamiento = datagen.flow(X_entrenamiento, y_entrenamiento, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WTqrVcKKMpI"
      },
      "source": [
        "tensorboardDenso_AD = TensorBoard(log_dir='logs/denso_AD')\n",
        "\n",
        "modeloDenso_AD.fit(\n",
        "    data_gen_entrenamiento,  # datos de entrenamiento\n",
        "    epochs=100, batch_size=32,\n",
        "    validation_data=(X_validacion, y_validacion),  # datos de prueba/validación\n",
        "    steps_per_epoch=int(np.ceil(len(X_entrenamiento) / float(32))),\n",
        "    validation_steps=int(np.ceil(len(X_validacion) / float(32))),\n",
        "    callbacks=[tensorboardDenso_AD]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJcJ8OAw8WOJ"
      },
      "source": [
        "tensorboardCNN_AD = TensorBoard(log_dir='logs-new/cnn_AD')\n",
        "\n",
        "modeloCNN_AD.fit(\n",
        "    data_gen_entrenamiento,\n",
        "    epochs=150, batch_size=32,\n",
        "    validation_data=(X_validacion, y_validacion),\n",
        "    steps_per_epoch=int(np.ceil(len(X_entrenamiento) / float(32))),\n",
        "    validation_steps=int(np.ceil(len(X_validacion) / float(32))),\n",
        "    callbacks=[tensorboardCNN_AD]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bwOIjLuyAsO"
      },
      "source": [
        "tensorboardCNN2_AD = TensorBoard(log_dir='logs/cnn2_AD')\n",
        "\n",
        "modeloCNN2_AD.fit(\n",
        "    data_gen_entrenamiento,\n",
        "    epochs=100, batch_size=32,\n",
        "    validation_data=(X_validacion, y_validacion),\n",
        "    steps_per_epoch=int(np.ceil(len(X_entrenamiento) / float(32))),\n",
        "    validation_steps=int(np.ceil(len(X_validacion) / float(32))),\n",
        "    callbacks=[tensorboardCNN2_AD]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tras entrenar los modelos vemos que:\n",
        "- el modelo denso no tiene sobreajuste, pero el entrenamiento y la validación se estancan\n",
        "- para el modelo CNN, la precisión va subiendo progresivamente, y la pérdida va bajando poco a poco; no hay sobreajuste, y estos resultados apuntan a que el modelo está aprendiendo\n",
        "- para el modelo CNN2, el resultado es similar al anterior\n",
        "  \n",
        "A modo de conclusión, el modelo que mejor ajuste tiene es el modelo CNN con datos aumentados, aunque podría mejorarse haciéndolo entrenar por más epochs p.e."
      ],
      "metadata": {
        "id": "VC5PcdgSBZa6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paso 5: exportar el modelo**"
      ],
      "metadata": {
        "id": "Flu7V5GpCzZB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BwhiRKiAwF0"
      },
      "source": [
        "modeloCNN_AD.save('perros-gatos-cnn-ad.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcUG8NoKA1ee"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8dSa1UzA4eW"
      },
      "source": [
        "!mkdir carpeta_salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEE6r07ZA6Mz"
      },
      "source": [
        "!tensorflowjs_converter --input_format keras perros-gatos-cnn-ad.h5 carpeta_salida"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}